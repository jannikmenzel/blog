<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Studienblog - Artikel</title>
    <link rel="stylesheet" href="/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/styles.css">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          jax: ["input/TeX", "output/HTML-CSS"],
          extensions: ["tex2jax.js"],
          "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] },
          tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], displayMath: [ ["$$","$$"], ["\\[", "\\]"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno" },
          TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } } },
          messageStyle: "none"
        });

        window.onload = function() {
            if (window.MathJax) {
                MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
            }
        };
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js" async></script>
</head>
<body>

<!-- Navigation -->
<nav class="navbar navbar-expand-lg navbar-dark">
    <div class="container">
        <a class="navbar-brand" href="https://jannikmenzel.me/blog">Studienblog</a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNav">
            <ul class="navbar-nav ms-auto">
                <li class="nav-item">
                    <a class="nav-link" href="https://jannikmenzel.me">Home</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/blog">Studienblog</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="https://github.com/jannikmenzel?tab=repositories">Projekte</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="https://github.com/jannikmenzel">Über mich</a>
                </li>
            </ul>
        </div>
    </div>
</nav>

<!-- Artikel-Inhalt -->
<div class="container my-5" id="blog-content">
    
<p><img src="/assets/cover-images/Artikel-15.jpg" alt="Blogbild"></p>
<h1 id="wie-lernen-chatbots-das-sprechen">Wie lernen Chatbots das
Sprechen?</h1>
<p><strong>Veröffentlicht am: 13. März 2025</strong></p>
<hr />
<h3 id="large-language-models">Large Language Models</h3>
<p>Large Language Models (LLMs) wie GPT-4, DeepSeek oder Google Gemini
sind beeindruckende Beispiele für moderne Künstliche Intelligenz (KI).
Sie simulieren menschenähnliche Kommunikation, sprechen mehr Sprachen
als ein Mensch je könnte und verfassen kreative Texte, Gedichte und
Lieder. Für viele ist die Existenz von LLMs ein beunruhigender Beweis
für den rasanten Fortschritt und die wachsende Präsenz künstlicher
Intelligenz. In diesem Artikel entschlüsseln wir die Funktionsweise
dieser künstlichen Intelligenzen und lichten die Ungewissheit, die seit
jeher über solche Technologien vorherrscht.</p>
<hr />
<h3 id="ein-blick-hinter-die-kulissen-wie-ein-llm-text-verarbeitet">Ein
Blick hinter die Kulissen: Wie ein LLM Text verarbeitet</h3>
<p>Um zu verstehen, wie LLMs arbeiten, müssen wir zunächst erörtern, wie
sie Texte verarbeiten. Statt Worte oder ganze Sätze als geschlossene
Einheit zu betrachten, zerlegen sie diese in kleinere,
bedeutungstragende Teile – sogenannte <strong>Tokens</strong>. Dabei
kann ein Token ein ganzes Wort, ein Wortteil oder lediglich ein
einzelnes Zeichen beinhalten. Ein Beispiel: Der Satz „Die Sonne geht im
Westen unter“ wird in die folgenden Tokens zerlegt:</p>
<pre><code>“Die” “Sonne” “geht” “im” “Westen” “unter”</code></pre>
<p>Diese Tokens werden anschließend durch ein Verfahren namens
<strong>Embedding</strong> in numerische Vektoren umgewandelt. Ein
Embedding ist eine mathematische Darstellung eines Tokens, die seine
Bedeutung im Kontext des Textes widerspiegelt. Man kann sich diesen
Prozess als das Anordnen von Punkten in einem hochdimensionalen Raum
vorstellen, wobei semantisch ähnliche Tokens nahe beieinander liegen,
sich also in Bedeutungsclustern sammeln. Das Token „Sonne“ liegt dabei
beispielsweise in der Nähe von Tokens wie „Licht“, „Tag“ oder
„Himmel“.</p>
<p>Ein wichtiger Bestandteil dieser Technik ist die
<strong>Self-Attention</strong>, die es dem Modell ermöglicht,
verschiedene Bereiche eines Textes miteinander zu verbinden – unabhängig
davon, wie weit sie voneinander entfernt sind. So kann beispielsweise
eine Verbindung zwischen „Sonne“ und „Westen“ hergestellt werden, selbst
wenn „Westen“ erst weiter hinten im Satz auftritt. Durch diesen
Mechanismus wird es dem LLM ermöglicht, den gesamten Kontext eines
Satzes zu erfassen und präzise Vorhersagen über die Bedeutung zu
treffen.</p>
<hr />
<h3 id="ein-gedankenspiel-das-semantische-verständnis-der-ki">Ein
Gedankenspiel: Das semantische Verständnis der KI</h3>
<p>Um das Verständnis von LLMs noch weiter zu vertiefen, können wir ein
Gedankenexperiment wagen. Man stelle sich vor, dass Wörter als Vektoren
in einem hochdimensionalen Raum interpretiert werden, wobei jeder Vektor
eine bestimmte semantische Bedeutung repräsentiert. Interessanterweise
können die Beziehungen zwischen diesen Vektoren durch geometrische
Abstände und Richtungen erfasst werden. So lässt sich durch algebraische
Operationen wie der Addition und Differenz zweier oder mehrerer Vektoren
ein tieferes semantisches Verständnis ableiten.</p>
<p>Beispielsweise ergibt die Differenz der Embeddings von „Mann“ und
„Frau“ in Kombination mit dem Token „Onkel“ einen Vektor, der dem Token
„Tante“ sehr nahekommt. Ein weiteres Beispiel kann durch die Vektoren
für Deutschland und Italien illustriert werden. Wenn man die Differenz
dieser beiden Vektoren zum Embedding des Tokens Hitler addiert, ergibt
sich ein Vektor, der dem Token Mussolini sehr nahekommt. Solche
semantischen Beziehungen sind nicht nur faszinierend, sondern auch
essenziell für das tiefere Sprachverständnis, das LLMs durch Training
erlernen. <a href="#Referenzen">[1]</a></p>
<hr />
<h3 id="von-der-theorie-zur-praxis-wie-llms-lernen">Von der Theorie zur
Praxis: Wie LLMs lernen</h3>
<p>Damit ein LLM die Fähigkeit zur “Sprache” entwickeln kann, wird es
mit Milliarden von Texten aus verschiedenen Quellen, wie Artikeln,
Büchern oder Websites trainiert. Dieser Trainingsprozess, auch als
<strong>Pretraining</strong> bezeichnet, beinhaltet das probabilistische
Vorhersagen des nächsten Wortes in einem Satz. Ein einfaches
Beispiel:</p>
<pre><code>Eingabe: &quot;Die Sonne geht im …&quot;

Vorhersage: &quot;Westen unter.&quot;</code></pre>
<p>Durch Milliarden solcher Vorhersagen entwickelt das Modell ein tiefes
Verständnis der Sprache. Jede Vorhersage und jedes erzeugte Wort basiert
auf Wahrscheinlichkeiten, die aus den gelernten Daten abgeleitet werden
und im Lernprozess gewichtet werden.</p>
<p>Es ist wichtig zu betonen, dass LLMs keine Vorkenntnisse, Logik oder
gesunden Menschenverstand besitzen. Sie treffen Entscheidungen auf Basis
der Daten, mit denen sie trainiert wurden. Wenn zum Beispiel wichtige
Informationen über eine bekannte Person wie Albert Einstein fehlen, kann
das Modell falsche oder ungenaue Verbindungen herstellen. In einem
solchen Fall könnte eine Vorhersage wie folgt aussehen:</p>
<pre><code>Eingabe: &quot;Albert Einstein war ein …&quot;

Vorhersage: &quot;Koch.&quot;</code></pre>
<p>In diesem Fall wählte das LLM <strong>Koch</strong> als die am
wahrscheinlichsten zutreffende Fortsetzung des Satzes. Aus einem
grammatikalischen Standpunkt gesehen, ist das auch richtig – lediglich
die Assoziation der Person Albert Einstein fehlte in der Evaluation.</p>
<hr />
<h3 id="wie-llms-zu-experten-werden">Wie LLMs zu Experten werden</h3>
<p>Nachdem ein LLM das Pretraining abgeschlossen hat, folgt oft eine
Feinabstimmung (Fine-Tuning), bei der das Modell auf spezifische
Aufgaben oder Daten angepasst wird. In dieser Phase wird das Modell mit
gezielten Datensätzen trainiert, um seine Leistung in bestimmten
Bereichen zu verbessern. Beispielsweise könnte ein Modell für die
medizinische Textverarbeitung oder die juristische Dokumentenanalyse
feinjustiert werden, um in diesen spezialisierten Bereichen präziser und
effizienter zu arbeiten.</p>
<hr />
<h3 id="fazit-chancen-und-herausforderungen-der-llms">Fazit: Chancen und
Herausforderungen der LLMs</h3>
<p>Die Entwicklung von Large Language Models zeigt, wie weit die
KI-Technologie bereits fortgeschritten ist. LLMs sind in der Lage,
komplexe sprachliche Zusammenhänge zu verstehen, Text zu generieren und
in unterschiedlichen Bereichen beeindruckende Leistungen zu erbringen.
Gleichzeitig bringen sie aber auch Herausforderungen mit sich. Die
Qualität der Trainingsdaten und die Gefahr von Fehlinformationen sind
nur zwei der vielen Fragestellungen, die im Umgang mit LLMs bedacht
werden müssen. Es ist wichtig zu verinnerlichen, dass LLMs im Grunde
nichts weiter als Vorhersagemaschinen sind. Sie analysieren Muster in
großen Datenmengen und treffen Entscheidungen basierend auf
Wahrscheinlichkeiten, ohne echtes Verständnis oder Kontext.</p>
<hr />
<h3 id="referenzen">Referenzen</h3>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=wjZofJX0v4M">Transformers
(how LLMs work) explained visually | DL5</a> von 3Blue1Brown</li>
<li><a href="https://scads.ai/">ScadsAI</a></li>
</ol>
</div>

<!-- Footer -->
<footer class="footer">
    <div class="container text-center">
        <p>&copy; 2025 Jannik Menzel. Alle Rechte vorbehalten.</p>
        <div class="social-links-container mt-3">
            <a href="https://www.instagram.com/jnk.mnz/" class="text-decoration-none text-light me-3" target="_blank"
               rel="noopener noreferrer">
                <img src="/assets/icons/instagram.svg" alt="Instagram Profil von Jannik Menzel" width="30">
            </a>
            <a href="https://dev.to/jnk_mnz" class="text-decoration-none text-light me-3" target="_blank"
               rel="noopener noreferrer">
                <img src="/assets/icons/dev.svg" alt="DEV Profil von Jannik Menzel" width="30">
            </a>
            <a href="https://github.com/jannikmenzel" class="text-decoration-none text-light" target="_blank"
               rel="noopener noreferrer">
                <img src="/assets/icons/github.svg" alt="GitHub Profil von Jannik Menzel" width="30">
            </a>
        </div>
    </div>
</footer>

<!-- Hintergrund -->
<div class="grid-background"></div>

<script src="/js/script.js"></script>
<script src="/js/spotlight.js"></script>
</body>
</html>